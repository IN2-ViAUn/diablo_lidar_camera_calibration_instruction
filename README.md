# Diablo机器人标定与定位真值计算指南

## 雷达与摄像头标定

采用Matlab的雷达相机标定工具：Lidar Camera Calibrator

### 数据采集

标定版制作，使用16cm大小的棋盘格，规格是7*9，不能有任何白边，如图所示

![棋盘格实体图](./images/chessboard.png)

采集时，需要同时采集雷达的点云数据（图下面板），以及摄像头的数据（图左上面板），我们使用的Azure Kinect2相机出厂自带内参（图右上面板），因此不用单独标定摄像机

![数据采集内容](./images/calib_data_collect.png)

我们录制了一个ros2的话题包，接下来开始数据处理

### 数据处理

数据处理需要我们从ros2包中导出点云以及图像数据，然后使用matlab进行标定。

要阅读导出代码，请浏览该项目目录下的`lidar_cam_calib_rosbag_exporter`目录，该节点将对相机以及深度相机还有雷达点云进行时间戳同步，然后考虑到我们使用的livox雷达点云的稀疏性，会累计3帧的雷达点云测量合并为一个pcd(因此在这三帧内，应该避免标定板有巨大的运动)。

最终我们将得到若干张rgb图片，深度图片和pcd点云文件，然后我们需要手动挑选出一些没有模糊，标定板在当前帧没有巨大位移的帧，用于matlab的标定，如图所示

![数据集示例内容](./images/calib_dataset.png)

matlab的工具不支持对图片进行去畸变处理，我们需要手动的先将图片进行去畸变，我们直接Azure Kinect相机驱动发布的话题读出畸变参数，然后使用本项目目录下`calib_image_undistortion.py`，修改其中的内参与畸变参数即可实现去畸变

接下来我们需要滤除pcd文件里面的其他杂点，以实现matlab更好的识别标定板所在的平面，请参考本项目目录下`filter_pcd_cpp`文件夹下的代码，并使用`CloudCompare`工具手动确认标定板的折射率与周围环境的折射率的明显区别，然后使用改程序尽可能率除掉除了标定板外地其他点。

然后此时得到两个文件夹，一个`png_undistorion`得到的是已经被去畸变过后的rgb图像，一个`pcd_filtered`得到的是已经滤除杂点的pcd文件，此时可以导入进matlab中进行标定

![matlab工具截图](./images/matlab_calib_tool.png)

如上图所示，导入后，请根据你的雷达自身的点云密度设置Cluter Threshold和Tolerance，第一个参数指定聚类平面的点之间的距离最大是多少，如果你的激光雷达点比较稀疏，那么就调大这个值，第二个参数指定对于识别到的点云团的非平面程度耐受度为多少，如果质量较差的点云，则调大这个值，然后点击Detect进行重新识别平面

另外可以切换到Select Chessboard界面手动的框选棋盘格的点云有哪些

然后需要给matlab一个初始的变换来让他能优化的比较好，此时可以手动量取大概的位移，然后使用python计算大概的旋转矩阵，此处不做赘述。

![matlab工具截图](./images/measure_extrinsics.png)

这样我们能够使用matlab测量出一个大致准确的外参，该4x4矩阵的含义是：**摄像机坐标系下的点经过这个变换，可以变到雷达坐标系下。**

